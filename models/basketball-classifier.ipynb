{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basketball-classifier.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1cILOwmQoTduWFxkHmh-xS1oM8Zh9sCQQ",
          "timestamp": 1518045430138
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "skkfi1Upj5qc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Free GPUs for All"
      ]
    },
    {
      "metadata": {
        "id": "UgJEUzstkD0B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The purpose is to showcase the power and flexibility of Google Colab to solve a classification problem. We will be leveraging Tensorflow's Imagenet pre-trained model to complete our task."
      ]
    },
    {
      "metadata": {
        "id": "QhtlKDNjkzyd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ]
    },
    {
      "metadata": {
        "id": "SkfprK8bm2YQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Importing Tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "D_lUGLOy5FTp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K-eh5k6-fOTw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Checking version of Tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "Iu_wtzqqN6_e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "50e1d184-ca9a-4a52-bd22-bebe80e22e4a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518046479904,
          "user_tz": 300,
          "elapsed": 2339,
          "user": {
            "displayName": "Ben Stewart",
            "photoUrl": "//lh3.googleusercontent.com/-kNBncLLafxE/AAAAAAAAAAI/AAAAAAAAAAc/o-S523GmxtM/s50-c-k-no/photo.jpg",
            "userId": "108211359438659781123"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip list | grep tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\u001b[0m\r\n",
            "tensorflow (1.4.1)\r\n",
            "tensorflow-tensorboard (0.4.0)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "beFJqatNnpoW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ensuring GPU setup for this notebook"
      ]
    },
    {
      "metadata": {
        "id": "u-d7T_GgnYwR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5e4ebc0-348e-48ad-a46f-19469cc347f9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518046475017,
          "user_tz": 300,
          "elapsed": 259,
          "user": {
            "displayName": "Ben Stewart",
            "photoUrl": "//lh3.googleusercontent.com/-kNBncLLafxE/AAAAAAAAAAI/AAAAAAAAAAc/o-S523GmxtM/s50-c-k-no/photo.jpg",
            "userId": "108211359438659781123"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "_MaPeEbblTfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download Pre-Trained Model"
      ]
    },
    {
      "metadata": {
        "id": "a7fFQXWWSoUo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ef7ddfb4-0d1c-488c-a862-ee3a281beade",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518041007287,
          "user_tz": 300,
          "elapsed": 11932,
          "user": {
            "displayName": "Ben Stewart",
            "photoUrl": "//lh3.googleusercontent.com/-kNBncLLafxE/AAAAAAAAAAI/AAAAAAAAAAc/o-S523GmxtM/s50-c-k-no/photo.jpg",
            "userId": "108211359438659781123"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Counting objects: 11513, done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 11513 (delta 2), reused 2 (delta 2), pack-reused 11504\u001b[K\n",
            "Receiving objects: 100% (11513/11513), 313.91 MiB | 42.61 MiB/s, done.\n",
            "Resolving deltas: 100% (6229/6229), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b5LnuJqFlngI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Running Our Model"
      ]
    },
    {
      "metadata": {
        "id": "XhnG32-Fd6my",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Directory where the imagenet model is located:"
      ]
    },
    {
      "metadata": {
        "id": "W-o9--Y2WeGe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d4993d7-7f35-4edb-d96e-2be24165e5d0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518042157224,
          "user_tz": 300,
          "elapsed": 255,
          "user": {
            "displayName": "Ben Stewart",
            "photoUrl": "//lh3.googleusercontent.com/-kNBncLLafxE/AAAAAAAAAAI/AAAAAAAAAAc/o-S523GmxtM/s50-c-k-no/photo.jpg",
            "userId": "108211359438659781123"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cd models/models/tutorials/image/imagenet/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/models/models/tutorials/image/imagenet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8HBzM_SpeKj_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Saving a picture of a basketball to our instance. We will use this image with the pre-trained imagenet classifier."
      ]
    },
    {
      "metadata": {
        "id": "BmgGZ5TlXTPh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "24df36b6-39a4-41f6-a6f7-b87370f8505c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518043629920,
          "user_tz": 300,
          "elapsed": 804,
          "user": {
            "displayName": "Ben Stewart",
            "photoUrl": "//lh3.googleusercontent.com/-kNBncLLafxE/AAAAAAAAAAI/AAAAAAAAAAc/o-S523GmxtM/s50-c-k-no/photo.jpg",
            "userId": "108211359438659781123"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://3.bp.blogspot.com/_qjlkTyHLyuw/TFt3adewwrI/AAAAAAAAAAk/Bdz2jz79Yjs/s1600/Basketball-large.png"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-02-07 22:47:09--  http://3.bp.blogspot.com/_qjlkTyHLyuw/TFt3adewwrI/AAAAAAAAAAk/Bdz2jz79Yjs/s1600/Basketball-large.png\r\n",
            "Resolving 3.bp.blogspot.com (3.bp.blogspot.com)... 74.125.141.132, 2607:f8b0:400c:c06::84\r\n",
            "Connecting to 3.bp.blogspot.com (3.bp.blogspot.com)|74.125.141.132|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 92358 (90K) [image/png]\n",
            "Saving to: ‘Basketball-large.png’\n",
            "\n",
            "Basketball-large.pn 100%[===================>]  90.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-02-07 22:47:09 (442 MB/s) - ‘Basketball-large.png’ saved [92358/92358]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LKBY6xEVeXdR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Running pre-trained classification model on our image of a basketball"
      ]
    },
    {
      "metadata": {
        "id": "NE9MIycSa-T-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "6f6d6174-54ec-4d3d-cd29-fbd9110ee8ee",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518043646901,
          "user_tz": 300,
          "elapsed": 5026,
          "user": {
            "displayName": "Ben Stewart",
            "photoUrl": "//lh3.googleusercontent.com/-kNBncLLafxE/AAAAAAAAAAI/AAAAAAAAAAc/o-S523GmxtM/s50-c-k-no/photo.jpg",
            "userId": "108211359438659781123"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!python classify_image.py --image_file Basketball-large.png"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n",
            "  from ._conv import register_converters as _register_converters\n",
            "2018-02-07 22:47:25.031609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-02-07 22:47:25.031962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 505.38MiB\n",
            "2018-02-07 22:47:25.032000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2018-02-07 22:47:25.361119: W tensorflow/core/framework/op_def_util.cc:334] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n",
            "2018-02-07 22:47:26.154511: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 533.62MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n",
            "2018-02-07 22:47:26.155268: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 192.66MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n",
            "2018-02-07 22:47:26.160128: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n",
            "2018-02-07 22:47:26.161376: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 289.05MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n",
            "2018-02-07 22:47:26.169735: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.91GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n",
            "2018-02-07 22:47:26.171665: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 195.75MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n",
            "2018-02-07 22:47:26.184128: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 200.27MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n",
            "2018-02-07 22:47:26.188223: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 300.41MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n",
            "2018-02-07 22:47:26.225470: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 205.72MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n",
            "2018-02-07 22:47:26.228326: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 205.72MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n",
            "basketball (score = 0.99916)\n",
            "orange (score = 0.00011)\n",
            "lifeboat (score = 0.00006)\n",
            "monarch, monarch butterfly, milkweed butterfly, Danaus plexippus (score = 0.00006)\n",
            "space heater (score = 0.00003)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qO7aAGA8eeuZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Results"
      ]
    },
    {
      "metadata": {
        "id": "bwHIaZJ5ejjD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our model is 99.9% certain that our basketball image is in fact a basketball. Feel free to test the model with any image and see what you get. The imagenet model is pretrained with ~1,000 categories."
      ]
    },
    {
      "metadata": {
        "id": "hKNGf1UV1LYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Common Errors"
      ]
    },
    {
      "metadata": {
        "id": "kljS2M0h1Tth",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "If running:\n",
        "```\n",
        "!python classify_image.py\n",
        "```\n",
        "yields:\n",
        "\n",
        "```\n",
        "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
        "  from ._conv import register_converters as _register_converters\n",
        ">> Downloading inception-2015-12-05.tgz 100.0%\n",
        "Successfully downloaded inception-2015-12-05.tgz 88931400 bytes.\n",
        "2018-02-07 22:06:11.433260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
        "2018-02-07 22:06:11.433505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: \n",
        "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
        "pciBusID: 0000:00:04.0\n",
        "totalMemory: 11.17GiB freeMemory: 163.62MiB\n",
        "2018-02-07 22:06:11.433538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
        "2018-02-07 22:06:11.442068: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 163.62M (171573248 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n",
        "2018-02-07 22:06:11.761083: W tensorflow/core/framework/op_def_util.cc:334] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n",
        "2018-02-07 22:06:11.979617: E tensorflow/stream_executor/cuda/cuda_blas.cc:366] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\n",
        "2018-02-07 22:06:12.055508: E tensorflow/stream_executor/cuda/cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
        "2018-02-07 22:06:12.055596: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\n",
        "2018-02-07 22:06:12.055615: F tensorflow/core/kernels/conv_ops.cc:667] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \n",
        "Aborted (core dumped)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "q4iE1a1M1elc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "df766f01-1e1c-4455-f481-b1bf25b4814a",
        "executionInfo": {
          "status": "error",
          "timestamp": 1518050175640,
          "user_tz": 300,
          "elapsed": 275,
          "user": {
            "displayName": "Ben Stewart",
            "photoUrl": "//lh3.googleusercontent.com/-kNBncLLafxE/AAAAAAAAAAI/AAAAAAAAAAc/o-S523GmxtM/s50-c-k-no/photo.jpg",
            "userId": "108211359438659781123"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "It is because of memory"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-a699aa47f15f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    It is because of memory\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "VM6ZmXy213Uk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is because of memory"
      ]
    },
    {
      "metadata": {
        "id": "C8uRrL9E17qM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Can run:"
      ]
    },
    {
      "metadata": {
        "id": "s83iaa7416tH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0e3b4382-653c-41f9-9858-2d6ff4e2b47c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518050206450,
          "user_tz": 300,
          "elapsed": 560,
          "user": {
            "displayName": "Ben Stewart",
            "photoUrl": "//lh3.googleusercontent.com/-kNBncLLafxE/AAAAAAAAAAI/AAAAAAAAAAc/o-S523GmxtM/s50-c-k-no/photo.jpg",
            "userId": "108211359438659781123"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!du -hs * | sort -rh | head -5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "893M\tcatsdogs\r\n",
            "120K\tdatalab\r\n",
            "88K\tsampleSubmission.csv\r\n",
            "4.0K\tdata\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xm5op74oaF3M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I just removed Python 2.7"
      ]
    }
  ]
}
